import os
import json
import google.generativeai as genai

# --- AI Model and API Configuration ---
print("Configuring Gemini API client for Theory Analysis...")
try:
    genai.configure(api_key=os.environ.get("GEMINI_API_KEY"))
    grading_model = genai.GenerativeModel('gemini-1.5-pro')
    print("Gemini model for theory analysis configured successfully.")
except Exception as e:
    print(f"CRITICAL ERROR: Failed to configure Gemini model: {e}")
    grading_model = None

# --- Main Gemini-Powered Grading Function ---
def analyze_theory_submission(question: str, student_answer_ocr: str) -> dict:
    """
    Uses Gemini to grade a student's theoretical answer.
    - First, checks for AI-generated content.
    - Fixes OCR typos in the student's answer.
    - Grades the answer against the question.
    - Generates a final summary remark.
    """
    if not grading_model or not student_answer_ocr:
        return {'score': 0.0, 'justification': 'Missing model or student answer.'}

    # --- Step 1: AI-Generated Content Check ---
    ai_check_result = _check_for_ai_content(student_answer_ocr)
    ai_prob = ai_check_result.get('ai_generated_probability', 0.0)
    ai_reason = ai_check_result.get('reasoning', 'N/A')

    if ai_prob > 0.20:
        # If probability is over 20%, fail the submission immediately.
        justification = (
            f"AI Content Check found a {ai_prob:.0%} likelihood that this submission was generated by AI, "
            f"which exceeds the 20% threshold. Reason: {ai_reason}. "
            "The submission has been assigned a score of 0."
        )
        return {'score': 0.0, 'justification': justification}

    # Step 2: Fix the OCR text before analysis
    print(f"Original OCR Text: {student_answer_ocr[:150]}...")
    corrected_answer = _fix_ocr_text_with_gemini(student_answer_ocr)
    print(f"Corrected Student Answer: {corrected_answer[:150]}...")

    # Step 3: Grade the corrected answer with a stricter prompt
    prompt = f"""
    As an expert AI university professor, your task is to evaluate a student's answer.
    Be highly discerning and strict. The student's answer must be factually correct to receive a high score.
    If the answer contains correct keywords but describes their relationship incorrectly (e.g., "resistance increases with current"), the score should be very low (under 0.2).

    Provide your response as a single, valid JSON object with no extra text or explanations.
    The JSON object must have two keys: "score" and "justification".
    - "score": A float value between 0.0 (completely wrong) and 1.0 (perfectly correct).
    - "justification": A brief, one-sentence explanation for the score, pointing out specific factual errors if any exist.

    ---
    Question: "{question}"
    ---
    Student's Answer: "{corrected_answer}"
    ---
    """
    
    grading_result = {}
    try:
        response = grading_model.generate_content(prompt)
        json_text = response.text.replace("```json", "").replace("```", "").strip()
        grading_result = json.loads(json_text)
    except Exception as e:
        print(f"Error calling Gemini for grading: {e}")
        grading_result = {'score': 0.0, 'justification': 'AI grading failed.'}

    # --- Step 4: Final aggregation and summary remark ---
    all_justifications = [
        f"AI Content Check: {ai_prob:.0%} likelihood of being AI-generated (below 20% threshold). Reason: {ai_reason}.",
        grading_result.get('justification', 'No detailed justification available.')
    ]
    final_summary = _generate_final_summary(all_justifications, question)
    
    detailed_justification = " | ".join(all_justifications)
    final_justification = f"{detailed_justification} | Final Remark: {final_summary}"
    
    return {'score': grading_result.get('score', 0.0), 'justification': final_justification}


# ----------------- HELPERS -----------------

def _fix_ocr_text_with_gemini(ocr_text: str) -> str:
    """Uses Gemini to correct spelling and grammar mistakes from OCR, without changing the core meaning."""
    if not grading_model or not ocr_text:
        return ocr_text
    
    prompt = f"""
    The following text was extracted from a document using OCR and may contain spelling mistakes. 
    Correct only the spelling and grammar. Do NOT change the factual meaning.
    Provide only the corrected text.

    Original Text:
    "{ocr_text}"
    """
    try:
        response = grading_model.generate_content(prompt)
        return response.text.strip()
    except Exception as e:
        print(f"Error fixing OCR text with Gemini: {e}")
        return ocr_text # Return original text if correction fails

def _check_for_ai_content(text: str) -> dict:
    """Uses Gemini to estimate the probability that a theoretical answer was AI-generated."""
    if not grading_model:
        return {'ai_generated_probability': 0.0, 'reasoning': 'AI model not available for check.'}
    
    prompt = f"""
    Analyze the following text. Based on patterns like overly formal language, perfectly structured paragraphs, lack of a personal or conversational voice, and the use of unnaturally complex vocabulary, estimate the probability that this text was generated by an AI.

    Provide your response as a single, valid JSON object with two keys:
    - "ai_generated_probability": A float between 0.0 (definitely human-written) and 1.0 (definitely AI-generated).
    - "reasoning": A brief, one-sentence explanation for your estimation.

    Text:
    ---
    {text}
    ---
    """
    try:
        response = grading_model.generate_content(prompt)
        json_text = response.text.replace("```json", "").replace("```", "").strip()
        return json.loads(json_text)
    except Exception as e:
        print(f"Error during AI content check: {e}")
        return {'ai_generated_probability': 0.0, 'reasoning': 'Failed to perform AI content analysis.'}

def _generate_final_summary(justifications: list, original_question: str) -> str:
    """Uses Gemini to generate a final summary remark based on part-by-part justifications."""
    if not grading_model or not justifications:
        return "Overall evaluation complete."

    detailed_feedback = "\n- ".join(justifications)

    prompt = f"""
    As an AI teaching assistant, you have evaluated a student's submission.
    Provide a single, concise summary remark (one or two sentences) of the student's overall performance.
    Synthesize the key points from the detailed evaluation. Do not mention the score or AI-generated content probability.

    Original Question:
    "{original_question}"

    Detailed Evaluation:
    - {detailed_feedback}

    ---
    Provide only the final summary text, without any introductory phrases.
    Example: "The answer correctly identifies the main concepts but lacks depth in the explanation of their relationship."
    """
    try:
        response = grading_model.generate_content(prompt)
        return response.text.strip()
    except Exception as e:
        print(f"Failed to generate final summary: {e}")
        return "Could not generate a final summary."
